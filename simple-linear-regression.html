<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <title>Simple Linear Regression</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="A Pelican Blog Atom Feed" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">A Pelican Blog </a></h1>
                <nav><ul>
                    <li><a href="/category/ab-testing.html">AB Testing</a></li>
                    <li><a href="/category/data-analysis.html">Data Analysis</a></li>
                    <li><a href="/category/finance.html">Finance</a></li>
                    <li class="active"><a href="/category/machine-learning.html">Machine Learning</a></li>
                    <li><a href="/category/recommendation-system.html">Recommendation System</a></li>
                    <li><a href="/category/self-driving-car.html">Self Driving Car</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/simple-linear-regression.html" rel="bookmark"
           title="Permalink to Simple Linear Regression">Simple Linear Regression</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2017-02-05T00:00:00+00:00">
                Published: Sun 05 February 2017
        </abbr>

<p>In <a href="/category/machine-learning.html">Machine Learning</a>.</p>

</footer><!-- /.post-info -->      <div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="o">*</span>

<span class="k">def</span> <span class="nf">computer_error_for_line_given_points</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">points</span><span class="p">):</span>
    <span class="c1"># Initialize error at 0</span>
    <span class="n">totalError</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="c1"># Loop through all points</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="c1"># Get x value</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Get y value</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Get squared difference and add to total error</span>
        <span class="n">totalError</span> <span class="o">+=</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">(</span><span class="n">m</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">b</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span>

    <span class="c1"># Return the average</span>
    <span class="k">return</span> <span class="n">totalError</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">gradient_descent_runner</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">starting_b</span><span class="p">,</span> <span class="n">starting_m</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">):</span>
    <span class="c1"># Starting b and m</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">starting_b</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">starting_m</span>

    <span class="c1"># Gradient descent</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
        <span class="c1"># Update b and m</span>
        <span class="n">b</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">step_gradient</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">array</span><span class="p">(</span><span class="n">points</span><span class="p">),</span> <span class="n">learning_rate</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">]</span>

<span class="c1"># Define step gradient function</span>
<span class="k">def</span> <span class="nf">step_gradient</span><span class="p">(</span><span class="n">b_current</span><span class="p">,</span> <span class="n">m_current</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">):</span>
    <span class="c1"># Initialize gradient values</span>
    <span class="n">b_gradient</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">m_gradient</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">points</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">N</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">points</span><span class="p">))</span>

        <span class="c1"># Direction w.r.t. b and m by computing partial derivatives of error function</span>
        <span class="n">b_gradient</span> <span class="o">+=</span> <span class="o">-</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">((</span><span class="n">m_current</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_current</span><span class="p">))</span>
        <span class="n">m_gradient</span> <span class="o">+=</span> <span class="o">-</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="n">N</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="p">((</span><span class="n">m_current</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">b_current</span><span class="p">))</span>

    <span class="c1"># Update b amd m values using partial derivatives</span>
    <span class="n">new_b</span> <span class="o">=</span> <span class="n">b_current</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">b_gradient</span><span class="p">)</span>
    <span class="n">new_m</span> <span class="o">=</span> <span class="n">m_current</span> <span class="o">-</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">m_gradient</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">new_b</span><span class="p">,</span> <span class="n">new_m</span><span class="p">]</span>



<span class="k">def</span> <span class="nf">run</span><span class="p">():</span>

    <span class="c1"># Step 1: collect data</span>
    <span class="n">points</span> <span class="o">=</span> <span class="n">genfromtxt</span><span class="p">(</span><span class="s1">&#39;data.csv&#39;</span><span class="p">,</span> <span class="n">delimiter</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="p">)</span>

    <span class="c1"># Step 2: define hyperparameters</span>

    <span class="c1"># Learning rate: rate of convergence of model</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.0001</span>

    <span class="c1"># Initialize y = mx + b values</span>
    <span class="n">initial_b</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">initial_m</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Number of iterations</span>
    <span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">1000</span>

    <span class="c1"># Step 3: train model</span>
    <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;Starting gradient descent at b = {0}, m = {1}, error = {2}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">initial_b</span><span class="p">,</span> <span class="n">initial_m</span><span class="p">,</span> <span class="n">computer_error_for_line_given_points</span><span class="p">(</span><span class="n">initial_b</span><span class="p">,</span> <span class="n">initial_m</span><span class="p">,</span> <span class="n">points</span><span class="p">)))</span>
    <span class="p">[</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">]</span> <span class="o">=</span> <span class="n">gradient_descent_runner</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">initial_b</span><span class="p">,</span> <span class="n">initial_m</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s1">&#39;Ending point at b = {1}, m = {2}, error = {3}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">computer_error_for_line_given_points</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">points</span><span class="p">)))</span>


<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">run</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre><span></span>Starting gradient descent at b = 0, m = 0, error = 2490.961189080058
Ending point at b = 0.08893651993741346, m = 1.4777440851894448, error = 572.7037959508043
</pre></div>


<div class="highlight"><pre><span></span>
</pre></div>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>